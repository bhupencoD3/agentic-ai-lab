{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "256fc91a",
   "metadata": {},
   "source": [
    "#### Chatbot Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25bdacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "os.environ['LANGSMITH_API_KEY']=os.getenv('LANGSMITH_API_KEY')\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')\n",
    "os.environ['LANGSMITH_TRACING']='true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19a67f14",
   "metadata": {},
   "outputs": [
    {
     "ename": "LangSmithConflictError",
     "evalue": "Conflict for /datasets. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Dataset with this name already exists.\"}')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agenticai_env/lib/python3.12/site-packages/langsmith/utils.py:159\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agenticai_env/lib/python3.12/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agenticai_env/lib/python3.12/site-packages/langsmith/client.py:937\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    931\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.session.request(\n\u001b[32m    932\u001b[39m         method,\n\u001b[32m    933\u001b[39m         _construct_url(\u001b[38;5;28mself\u001b[39m.api_url, pathname),\n\u001b[32m    934\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    935\u001b[39m         **request_kwargs,\n\u001b[32m    936\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m937\u001b[39m \u001b[43mls_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agenticai_env/lib/python3.12/site-packages/langsmith/utils.py:161\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m requests.HTTPError(\u001b[38;5;28mstr\u001b[39m(e), response.text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mHTTPError\u001b[39m: [Errno 409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets] {\"detail\":\"Dataset with this name already exists.\"}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mLangSmithConflictError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m client=Client()\n\u001b[32m      4\u001b[39m dataset_name = \u001b[33m'\u001b[39m\u001b[33msimple_chatbot_evaluation\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m dataset = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m examples = [\n\u001b[32m      8\u001b[39m     {\n\u001b[32m      9\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33minputs\u001b[39m\u001b[33m\"\u001b[39m: {\u001b[33m\"\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mWhat is an iterator in Python?\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m   (...)\u001b[39m\u001b[32m     47\u001b[39m     }\n\u001b[32m     48\u001b[39m ]\n\u001b[32m     50\u001b[39m \u001b[38;5;66;03m# Upload each example\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agenticai_env/lib/python3.12/site-packages/langsmith/client.py:3797\u001b[39m, in \u001b[36mClient.create_dataset\u001b[39m\u001b[34m(self, dataset_name, description, data_type, inputs_schema, outputs_schema, transformations, metadata)\u001b[39m\n\u001b[32m   3794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m outputs_schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3795\u001b[39m     dataset[\u001b[33m\"\u001b[39m\u001b[33moutputs_schema_definition\u001b[39m\u001b[33m\"\u001b[39m] = outputs_schema\n\u001b[32m-> \u001b[39m\u001b[32m3797\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3798\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3799\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/datasets\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3800\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mContent-Type\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapplication/json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3801\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_orjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3802\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3803\u001b[39m ls_utils.raise_for_status_with_text(response)\n\u001b[32m   3805\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ls_schemas.Dataset(\n\u001b[32m   3806\u001b[39m     **response.json(),\n\u001b[32m   3807\u001b[39m     _host_url=\u001b[38;5;28mself\u001b[39m._host_url,\n\u001b[32m   3808\u001b[39m     _tenant_id=\u001b[38;5;28mself\u001b[39m._get_optional_tenant_id(),\n\u001b[32m   3809\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/agenticai_env/lib/python3.12/site-packages/langsmith/client.py:982\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    977\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithNotFoundError(\n\u001b[32m    978\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mResource not found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    979\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    980\u001b[39m     )\n\u001b[32m    981\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m409\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m982\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithConflictError(\n\u001b[32m    983\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConflict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    984\u001b[39m     )\n\u001b[32m    985\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m response.status_code == \u001b[32m403\u001b[39m:\n\u001b[32m    986\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mLangSmithConflictError\u001b[39m: Conflict for /datasets. HTTPError('409 Client Error: Conflict for url: https://api.smith.langchain.com/datasets', '{\"detail\":\"Dataset with this name already exists.\"}')"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "client=Client()\n",
    "\n",
    "dataset_name = 'simple_chatbot_evaluation'\n",
    "dataset = client.create_dataset(dataset_name=dataset_name)\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What is an iterator in Python?\"},\n",
    "        \"outputs\": {\"answer\": \"An iterator in Python is an object that implements the __iter__() and __next__() methods, allowing iteration over elements one at a time.\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What is the purpose of the attention mechanism in NLP?\"},\n",
    "        \"outputs\": {\"answer\": \"The attention mechanism helps models focus on the most relevant parts of the input sequence when generating output, improving performance in tasks like translation and summarization.\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Who is the founder of OpenAI?\"},\n",
    "        \"outputs\": {\"answer\": \"OpenAI was co-founded by Elon Musk, Sam Altman, Greg Brockman, Ilya Sutskever, John Schulman, and Wojciech Zaremba.\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What is RAG in LLMs?\"},\n",
    "        \"outputs\": {\"answer\": \"RAG, or Retrieval-Augmented Generation, combines retrieval from an external knowledge base with generative models to provide more accurate and grounded responses.\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Tell me about the dummy company LexoraTech.\"},\n",
    "        \"outputs\": {\"answer\": \"LexoraTech is a fictional AI research and consulting firm specializing in machine learning solutions, regulatory compliance, and enterprise automation.\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What is LangChain?\"},\n",
    "        \"outputs\": {\"answer\": \"LangChain is a framework for building applications with large language models by integrating retrieval, chaining, and external tools.\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What is the capital of France?\"},\n",
    "        \"outputs\": {\"answer\": \"The capital of France is Paris.\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Who won the FIFA World Cup in 2018?\"},\n",
    "        \"outputs\": {\"answer\": \"France won the FIFA World Cup in 2018, defeating Croatia 4-2 in the final.\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"Explain the difference between iterable and iterator in Python.\"},\n",
    "        \"outputs\": {\"answer\": \"An iterable is any object capable of returning its elements one at a time, like lists or strings, and implements __iter__(). An iterator is the object returned by __iter__() that produces elements using __next__().\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What is the main benefit of Transformers over RNNs?\"},\n",
    "        \"outputs\": {\"answer\": \"Transformers can process sequences in parallel using self-attention, avoiding the sequential bottleneck of RNNs and enabling better handling of long-range dependencies.\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "# Upload each example\n",
    "for ex in examples:\n",
    "    client.create_example(\n",
    "        dataset_id=dataset.id,\n",
    "        inputs=ex[\"inputs\"],\n",
    "        outputs=ex[\"outputs\"]\n",
    "    )\n",
    "\n",
    "print(\"All examples uploaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4133c72c",
   "metadata": {},
   "source": [
    "#### Define Metrics(LLM as a Judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7c1deef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langsmith import wrappers\n",
    "\n",
    "\n",
    "openai_client=wrappers.wrap_openai(\n",
    "    openai.OpenAI()\n",
    ")\n",
    "\n",
    "eval_instruction=\"you are an expert professor specialized in grading student's answer to questions \" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99ff30ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correctness(inputs:dict,outputs:dict,reference_outputs:dict) -> bool:\n",
    "    user_content=f\"\"\"You are grading the following question:\n",
    "    {inputs['question']}\n",
    "Here is the real answer:\n",
    "{reference_outputs['answer']}\n",
    "You are grading the following predicted answer:\n",
    "{outputs['response']}\n",
    "Respond with CORRECT or INCORRECT:\n",
    "Grade:\n",
    "\"\"\"\n",
    "    response=openai.chat.completions.create(\n",
    "    model='gpt-4o-mini',\n",
    "    temperature=0,\n",
    "    messages=[\n",
    "        {'role':\"system\",'content':eval_instruction},\n",
    "        {'role':'user','content':user_content}\n",
    "    ]\n",
    ").choices[0].message.content\n",
    "    \n",
    "\n",
    "    return response==\"CORRECT\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fd873b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concision(outputs:dict,reference_outputs:dict)->bool:\n",
    "    return int(len(outputs['response'])) < 2 * len(reference_outputs['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c202faa",
   "metadata": {},
   "source": [
    "#### Run Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fd3226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_instruction=\"Respond to the user question in a short,concise manner (one short sentence).\"\n",
    "\n",
    "def my_app(question:str,model:str='gpt-4o-mini',instruction:str=default_instruction)-> str:\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=model,\n",
    "        temperature=0,\n",
    "        messages=[{'role':'system','content':instruction},\n",
    "                  {'role':'user','content':question}],\n",
    "    ).choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f53100f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc798a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_target(inputs:str) -> dict:\n",
    "    return {'response':my_app[inputs['question']]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c32d5959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment_result=client.evaluate(\n",
    "#     ls_target,\n",
    "#     data=dataset_name,\n",
    "#     evaluators=[correctness,concision],\n",
    "#     experiment_prefix=\"openai-4o-mini-chatbot\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5019d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
