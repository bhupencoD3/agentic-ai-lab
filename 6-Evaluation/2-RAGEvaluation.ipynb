{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d47aec0",
   "metadata": {},
   "source": [
    "#### Evaluation of RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65255d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "urls=[\n",
    "    'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/',\n",
    "    'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/',\n",
    "    'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
    "]\n",
    "\n",
    "\n",
    "docs=[WebBaseLoader(urls).load() for url in urls]\n",
    "\n",
    "docs_list=[item for sublist in docs for item in sublist]\n",
    "text_splitter=RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250,chunk_overlap=0\n",
    ")\n",
    "\n",
    "docs_splits=text_splitter.split_documents(docs_list)\n",
    "\n",
    "vector_store=InMemoryVectorStore.from_documents(\n",
    "    documents=docs_splits,\n",
    "    embedding=OpenAIEmbeddings(model='text-embedding-3-small')\n",
    ")\n",
    "\n",
    "retriever=vector_store.as_retriever(k=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52ded809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='0b8ae5cd-645d-4d52-8779-b3d59ef3092b', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'),\n",
       " Document(id='55095885-eacd-4984-8b64-05d21e39f6e8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'),\n",
       " Document(id='46bd667e-9acf-4af8-a638-deb5b0a3bf44', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'),\n",
       " Document(id='3c009f0c-864b-41bb-9f7d-f35778f40dd7', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content=\"LLM Powered Autonomous Agents | Lil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLil'Log\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n|\\n\\n\\n\\n\\n\\n\\nPosts\\n\\n\\n\\n\\nArchive\\n\\n\\n\\n\\nSearch\\n\\n\\n\\n\\nTags\\n\\n\\n\\n\\nFAQ\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n      LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\n \\n\\n\\nTable of Contents\\n\\n\\n\\nAgent System Overview\\n\\nComponent One: Planning\\n\\nTask Decomposition\\n\\nSelf-Reflection\\n\\n\\nComponent Two: Memory\\n\\nTypes of Memory\\n\\nMaximum Inner Product Search (MIPS)\\n\\n\\nComponent Three: Tool Use\\n\\nCase Studies\\n\\nScientific Discovery Agent\\n\\nGenerative Agents Simulation\\n\\nProof-of-Concept Examples\\n\\n\\nChallenges\\n\\nCitation\\n\\nReferences\")]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('What is the agents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3f79ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "llm=init_chat_model(model='openai:gpt-4o-mini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ebedefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable\n",
    "\n",
    "@traceable\n",
    "def rag_bot(question:str)->dict:\n",
    "    docs=retriever.invoke(question)\n",
    "    docs_string=\" \".join(doc.page_content for doc in docs)\n",
    "\n",
    "    instruction=f\"\"\"You are a helpful assistant who is good at analyzing source information and answering questions.\n",
    "     use three sentences maximum and keep the answer concise\n",
    "     \n",
    "     Documents:{docs_string}\"\"\"\n",
    "    \n",
    "    ai_response=llm.invoke([\n",
    "        {'role':'system','content':instruction},\n",
    "        {'role':'user','content':question}\n",
    "    ])\n",
    "\n",
    "    return {'answer':ai_response.content,'documents':docs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b8a95c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Agents, in this context, refer to virtual characters controlled by LLM-powered systems that simulate human behavior and interactions within a constructed environment, such as a sandbox. They utilize mechanisms like memory, planning, and reflection to behave based on past experiences and interact with other agents.',\n",
       " 'documents': [Document(id='0b8ae5cd-645d-4d52-8779-b3d59ef3092b', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'),\n",
       "  Document(id='46bd667e-9acf-4af8-a638-deb5b0a3bf44', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'),\n",
       "  Document(id='55095885-eacd-4984-8b64-05d21e39f6e8', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='They also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.'),\n",
       "  Document(id='658474d2-f951-4408-9fa4-a7f463552944', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content=\"Planning is essentially in order to optimize believability at the moment vs in time.\\nPrompt template: {Intro of an agent X}. Here is X's plan today in broad strokes: 1)\\nRelationships between agents and observations of one agent by another are all taken into consideration for planning and reacting.\\nEnvironment information is present in a tree structure.\\n\\n\\n\\n\\n\\nThe generative agent architecture. (Image source: Park et al. 2023)\")]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_bot(\"What is agents?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d90f149a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All examples uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "from langsmith import Client\n",
    "client=Client()\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What is a threat model in adversarial attacks on large language models?\"},\n",
    "        \"outputs\": {\"answer\": \"According to Lilian Weng, a threat model in adversarial attacks on LLMs refers to the assumptions about what the adversary knows, what access they have (e.g. inference only vs. white-box), and what kind of behavior (classification or generation) is being attacked at inference time while the model weights are fixed.\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What is the difference between white-box and black-box adversarial attacks on LLMs?\"},\n",
    "        \"outputs\": {\"answer\": \"White-box attacks assume access to model weights, architecture, or training process, allowing use of gradient signals, while black-box attacks only allow interaction through input/output, with no direct access to internal parameters.\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What is token manipulation as a type of adversarial attack?\"},\n",
    "        \"outputs\": {\"answer\": \"Token manipulation is a black-box adversarial method where a small number of tokens in text input are altered—using synonyms, insertions, deletions or swaps—while preserving the overall semantics, in order to trigger erroneous or unsafe outputs.\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What is a jailbreak prompt and how is it used in adversarial attacks?\"},\n",
    "        \"outputs\": {\"answer\": \"A jailbreak prompt is a heuristic based prompt designed to bypass or subvert the model’s built-in safety or refusal behavior—things like prefix injection, style injection, suppression of refusal formats, role-playing attacks are examples, all intended to induce the model to produce content it should refuse under normal safety constraints.\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"How does human red-teaming work in mitigating adversarial attacks?\"},\n",
    "        \"outputs\": {\"answer\": \"Human red-teaming involves people crafting adversarial examples to test model safety, often with tools that highlight token importance or allow prompt rewrites, and results of red teams are used to train classifiers or adjust safety logic.\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What is prompt engineering according to Lilian Weng’s blog?\"},\n",
    "        \"outputs\": {\"answer\": \"Prompt engineering is the practice of designing the wording, format, and structure of prompts—for example, chain-of-thought, zero-shot, few-shot, or instruction templates—in order to guide performance of LLMs more reliably and reduce errors or ambiguity.\"}\n",
    "    },\n",
    "    {\n",
    "        \"inputs\": {\"question\": \"What are agents in the context of LLMs as explained in the 'Agent' blog by Lilian Weng?\"},\n",
    "        \"outputs\": {\"answer\": \"Agents are systems built on LLMs that can use external tools, perform actions, plan, retrieve knowledge, combine reasoning, maintain context, and act adaptively rather than just responding passively to prompts.\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "dataset_name='rag-evaluation'\n",
    "\n",
    "dataset=client.create_dataset(dataset_name=dataset_name)\n",
    "\n",
    "for ex in examples:\n",
    "    client.create_example(\n",
    "        dataset_id=dataset.id,\n",
    "        inputs=ex[\"inputs\"],\n",
    "        outputs=ex[\"outputs\"]\n",
    "    )\n",
    "\n",
    "print(\"All examples uploaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1a8c8a",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d53dde",
   "metadata": {},
   "source": [
    "1.Correctness:Response vs Reference Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5232b6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing_extensions import Annotated\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ======= 1. Correctness =======\n",
    "class CorrectnessGrade(BaseModel):\n",
    "    explanation: Annotated[str, \"Explain your reasoning\"]\n",
    "    correct: Annotated[bool, \"True if correct, False otherwise\"]\n",
    "\n",
    "correctness_instruction = \"\"\"You are grading a quiz.\n",
    "Given a QUESTION, GROUND TRUTH ANSWER, and STUDENT ANSWER:\n",
    "\n",
    "1) Grade the student answer based ONLY on factual accuracy.\n",
    "2) It is OK if the student answer has extra correct info.\n",
    "3) No conflicting statements allowed.\n",
    "\n",
    "Explain reasoning step-by-step.\"\"\"\n",
    "\n",
    "correctness_llm = ChatOpenAI(model='gpt-4o-mini', temperature=0).with_structured_output(\n",
    "    CorrectnessGrade, method='json_schema', strict=True\n",
    ")\n",
    "\n",
    "def correctness(inputs: dict, outputs: dict, reference_outputs: dict) -> bool:\n",
    "    prompt = f\"\"\"\n",
    "Question: {inputs['question']}\n",
    "Ground Truth Answer: {reference_outputs['answer']}\n",
    "Student Answer: {outputs['answer']}\n",
    "\"\"\"\n",
    "    grade = correctness_llm.invoke([\n",
    "        {'role': 'system', 'content': correctness_instruction},\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ])\n",
    "    return grade.correct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ec3bbe",
   "metadata": {},
   "source": [
    "##### 2.Relevance:Response vs Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b4e83c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RelevanceGrade(BaseModel):\n",
    "    explanation: Annotated[str, \"Explain your reasoning\"]\n",
    "    relevant: Annotated[bool, \"True if relevant, False otherwise\"]\n",
    "\n",
    "relevance_instruction = \"\"\"You are grading a quiz.\n",
    "Given QUESTION and STUDENT ANSWER:\n",
    "\n",
    "1) Check if the answer is concise and relevant.\n",
    "2) Answer must help answer the question.\n",
    "\n",
    "Explain reasoning step-by-step.\"\"\"\n",
    "\n",
    "relevance_llm = ChatOpenAI(model='gpt-4o-mini', temperature=0).with_structured_output(\n",
    "    RelevanceGrade, method='json_schema', strict=True\n",
    ")\n",
    "\n",
    "def relevance(inputs: dict, outputs: dict) -> bool:\n",
    "    prompt = f\"\"\"\n",
    "Question: {inputs['question']}\n",
    "Student Answer: {outputs['answer']}\n",
    "\"\"\"\n",
    "    grade = relevance_llm.invoke([\n",
    "        {'role': 'system', 'content': relevance_instruction},\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ])\n",
    "    return grade.relevant  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0ccac76",
   "metadata": {},
   "source": [
    "##### 3.Groundeness:Respons vs retrieved docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "98718e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= 3. Groundedness =======\n",
    "class GroundGrade(BaseModel):\n",
    "    explanation: Annotated[str, \"Explain your reasoning\"]\n",
    "    grounded: Annotated[bool, \"True if grounded, False if hallucinates\"]\n",
    "\n",
    "grounded_instruction = \"\"\"You are grading a quiz.\n",
    "Given FACTS and STUDENT ANSWER:\n",
    "\n",
    "1) Check that the answer is grounded in the facts.\n",
    "2) No hallucinated information allowed.\n",
    "\n",
    "Explain reasoning step-by-step.\"\"\"\n",
    "\n",
    "grounded_llm = ChatOpenAI(model='gpt-4o-mini', temperature=0).with_structured_output(\n",
    "    GroundGrade, method='json_schema', strict=True\n",
    ")\n",
    "\n",
    "def groundedness(inputs: dict, outputs: dict) -> bool:\n",
    "    doc_string = \"\\n\\n\".join(doc.page_content for doc in outputs['documents'])\n",
    "    prompt = f\"\"\"\n",
    "Facts: {doc_string}\n",
    "Student Answer: {outputs['answer']}\n",
    "\"\"\"\n",
    "    grade = grounded_llm.invoke([\n",
    "        {'role': 'system', 'content': grounded_instruction},\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ])\n",
    "    return grade.grounded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28239f52",
   "metadata": {},
   "source": [
    "4.Retrieval Relevance:Retrieved docs vs input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5be9c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======= 4. Retrieval Relevance =======\n",
    "class RetrievalRelevanceGrade(BaseModel):\n",
    "    explanation: Annotated[str, \"Explain your reasoning\"]\n",
    "    relevant: Annotated[bool, \"True if retrieved documents relevant, False otherwise\"]\n",
    "\n",
    "retrieval_relevance_instruction = \"\"\"You are grading a quiz.\n",
    "Given QUESTION and FACTS:\n",
    "\n",
    "1) Identify facts completely unrelated to the question.\n",
    "2) If any keywords or semantic meaning match the question, mark as relevant.\n",
    "\n",
    "Explain reasoning step-by-step.\"\"\"\n",
    "\n",
    "retrieval_relevance_llm = ChatOpenAI(model='gpt-4o-mini', temperature=0).with_structured_output(\n",
    "    RetrievalRelevanceGrade, method='json_schema', strict=True\n",
    ")\n",
    "\n",
    "def retrieval_relevance(inputs: dict, outputs: dict) -> bool:\n",
    "    doc_string = \"\\n\\n\".join(doc.page_content for doc in outputs['documents'])\n",
    "    prompt = f\"\"\"\n",
    "Question: {inputs['question']}\n",
    "Facts: {doc_string}\n",
    "\"\"\"\n",
    "    grade = retrieval_relevance_llm.invoke([\n",
    "        {'role': 'system', 'content': retrieval_relevance_instruction},\n",
    "        {'role': 'user', 'content': prompt}\n",
    "    ])\n",
    "    return grade.relevant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "985d5722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'rag-doc-relevance-6e241a47' at:\n",
      "https://smith.langchain.com/o/6a377c92-e664-4557-95a3-a1e917bdfc35/datasets/72a14497-cd85-41d3-9601-15bc10c14845/compare?selectedSessions=6cf65507-0100-41f4-a3cf-fdf18bf3d206\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [02:15, 19.30s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<ExperimentResults rag-doc-relevance-6e241a47>"
      ],
      "text/plain": [
       "<ExperimentResults rag-doc-relevance-6e241a47>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def target(input:dict) -> dict:\n",
    "    return rag_bot(input['question'])\n",
    "\n",
    "experimental_results=client.evaluate(\n",
    "    target,\n",
    "    data=dataset_name,\n",
    "    evaluators=[correctness,groundedness,relevance,retrieval_relevance],\n",
    "    experiment_prefix='rag-doc-relevance',\n",
    "    metadata={'version':'LCEL context,gpt-4-0125-preview'},\n",
    ")\n",
    "experimental_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
