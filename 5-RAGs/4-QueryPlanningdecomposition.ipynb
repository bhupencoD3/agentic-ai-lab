{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ad6fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import TextLoader,WebBaseLoader\n",
    "from langgraph.graph import StateGraph,END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf46aecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x7fe712cafaa0>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x7fe71264aff0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['GROQ_API_KEY']=os.getenv('GROQ_API_KEY')\n",
    "llm=init_chat_model('groq:gemma2-9b-it')\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994093c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls=[\n",
    "    'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
    "    'https://lilianweng.github.io/posts/2023-04-22-diffusion-video/'\n",
    "]\n",
    "\n",
    "docs=[]\n",
    "for url in urls:\n",
    "    docs.extend(WebBaseLoader(url).load())\n",
    "\n",
    "splitter=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=100)\n",
    "chunks=splitter.split_documents(docs)\n",
    "\n",
    "vectorStore=FAISS.from_documents(chunks,OpenAIEmbeddings(model='text-embedding-3-small'))\n",
    "retriever=vectorStore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f3f9ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGState(BaseModel):\n",
    "    question:str\n",
    "    sub_question:List[str]=[]\n",
    "    retrieved_docs:List[Document]=[]\n",
    "    answer:str=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e6c56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plan_query(state:RAGState) -> RAGState:\n",
    "    prompt=f\"\"\"Break the following complex question into 2-3 sub-questions:\n",
    "    Question:{state.question}\n",
    "    Sub-question:\n",
    "    \"\"\"\n",
    "\n",
    "    result=llm.invoke(prompt)\n",
    "    sub_questions=[line.strip(\"- \").strip() for line in result.content.strip().split(\"\\n\") if line.strip()]\n",
    "    return RAGState(question=state.question,sub_question=sub_questions)\n",
    "\n",
    "\n",
    "\n",
    "def retrieve_for_each(state:RAGState)->RAGState:\n",
    "    all_docs=[]\n",
    "    for sub in state.sub_question:\n",
    "        docs=retriever.invoke(sub)\n",
    "        all_docs.extend(docs)\n",
    "\n",
    "    return RAGState(question=state.question,sub_question=state.sub_question,retrieved_docs=all_docs)\n",
    "\n",
    "\n",
    "def generate_final_answer(state:RAGState) -> RAGState:\n",
    "    context=\"\\n\\n\".join([doc.page_content for doc in state.retrieved_docs])\n",
    "    prompt=f\"\"\"Use the context below to answer the question.\n",
    "    context:{context}\\n\\n question:{state.question}\"\"\"\n",
    "\n",
    "    answer=llm.invoke(prompt).content\n",
    "    return RAGState(question=state.question,sub_question=state.sub_question,retrieved_docs=state.retrieved_docs,answer=answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "593c3d53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7fe70c717080>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "builder=StateGraph(RAGState)\n",
    "\n",
    "builder.add_node('planner',plan_query)\n",
    "builder.add_node('retriever',retrieve_for_each)\n",
    "builder.add_node('responder',generate_final_answer)\n",
    "\n",
    "builder.set_entry_point('planner')\n",
    "builder.add_edge('planner','retriever')\n",
    "builder.add_edge('retriever','responder')\n",
    "builder.add_edge('responder',END)\n",
    "\n",
    "graph=builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5903daa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'How basically attention mechansim changed the overview of recurrent models and what was dominated the sequence modeling before attention mechanism? ', 'sub_question': ['Here are some sub-questions that break down the complex query:', '* **Sub-question 1:** What were the limitations of recurrent models (like RNNs) in handling long sequences before the introduction of attention mechanisms?', '* **Sub-question 2:** How do attention mechanisms address these limitations and improve the performance of sequence modeling tasks?', '* **Sub-question 3:** What were the dominant sequence modeling approaches before attention mechanisms gained popularity? (This could explore methods like traditional RNNs, convolutional networks for sequences, etc.)', \"Let me know if you'd like to explore any of these sub-questions in more detail!\"], 'retrieved_docs': [Document(id='041242b2-ea53-4a9b-b861-51e06f1a89bc', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='through the half that is closest to the query and then aggregates the results. The idea is quite related to KD tree but a lot more scalable.'), Document(id='321eceb7-2ed5-4ad0-9bd6-dfd5cdb0b218', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#'), Document(id='3607e193-50dc-4b51-b4ca-dcd76e8c142d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='},\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {'), Document(id='80f3319d-1d09-475d-a27e-521a4a27deab', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Prompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions'), Document(id='3cc3bb60-2fb3-4198-9eb9-4f5a49279a33', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='In reality, the model has limited context window length, so episodes should be short enough to construct multi-episode history. Multi-episodic contexts of 2-4 episodes are necessary to learn a near-optimal in-context RL algorithm. The emergence of in-context RL requires long enough context.'), Document(id='6f87538a-d493-49e7-b662-463b84dd4209', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389'), Document(id='1880c0b7-ed28-4469-82fa-d6674dcacd53', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Categorization of human memory.\\n\\nWe can roughly consider the following mappings:\\n\\nSensory memory as learning embedding representations for raw inputs, including text, image or other modalities;\\nShort-term memory as in-context learning. It is short and finite, as it is restricted by the finite context window length of Transformer.\\nLong-term memory as the external vector store that the agent can attend to at query time, accessible via fast retrieval.'), Document(id='3f27c43d-b056-4a0f-9754-8a89c0b86df2', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Memory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use'), Document(id='389063cf-3b75-4ba0-be07-804baef10f7a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='to produce better output based on the feedback sequence. The model can optionally receive multiple rounds of instructions with human annotators at test time.'), Document(id='4749a37b-ccea-4451-8a17-41020f81c78d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='After fine-tuning with CoH, the model can follow instructions to produce outputs with incremental improvement in a sequence. (Image source: Liu et al. 2023)'), Document(id='6f87538a-d493-49e7-b662-463b84dd4209', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389'), Document(id='3d007987-6154-4c6e-8fbb-4a9dc153695e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).'), Document(id='6f87538a-d493-49e7-b662-463b84dd4209', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='[3] Liu et al. “Chain of Hindsight Aligns Language Models with Feedback\\n“ arXiv preprint arXiv:2302.02676 (2023).\\n[4] Liu et al. “LLM+P: Empowering Large Language Models with Optimal Planning Proficiency” arXiv preprint arXiv:2304.11477 (2023).\\n[5] Yao et al. “ReAct: Synergizing reasoning and acting in language models.” ICLR 2023.\\n[6] Google Blog. “Announcing ScaNN: Efficient Vector Similarity Search” July 28, 2020.\\n[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389'), Document(id='b14aef15-92e7-4923-9643-dae60cb25894', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='[7] https://chat.openai.com/share/46ff149e-a4c7-4dd7-a800-fc4a642ea389\\n[8] Shinn & Labash. “Reflexion: an autonomous agent with dynamic memory and self-reflection” arXiv preprint arXiv:2303.11366 (2023).\\n[9] Laskin et al. “In-context Reinforcement Learning with Algorithm Distillation” ICLR 2023.\\n[10] Karpas et al. “MRKL Systems A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning.” arXiv preprint arXiv:2205.00445 (2022).'), Document(id='3d007987-6154-4c6e-8fbb-4a9dc153695e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='[11] Nakano et al. “Webgpt: Browser-assisted question-answering with human feedback.” arXiv preprint arXiv:2112.09332 (2021).\\n[12] Parisi et al. “TALM: Tool Augmented Language Models”\\n[13] Schick et al. “Toolformer: Language Models Can Teach Themselves to Use Tools.” arXiv preprint arXiv:2302.04761 (2023).\\n[14] Weaviate Blog. Why is Vector Search so fast? Sep 13, 2022.\\n[15] Li et al. “API-Bank: A Benchmark for Tool-Augmented LLMs” arXiv preprint arXiv:2304.08244 (2023).'), Document(id='641040c3-28d2-42fa-88b5-218472c05507', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='hindsight feedback. Assume the feedback tuples are ranked by reward, $r_n \\\\geq r_{n-1} \\\\geq \\\\dots \\\\geq r_1$ The process is supervised fine-tuning where the data is a sequence in the form of $\\\\tau_h = (x, z_i, y_i, z_j, y_j, \\\\dots, z_n, y_n)$, where $\\\\leq i \\\\leq j \\\\leq n$. The model is finetuned to only predict $y_n$ where conditioned on the sequence prefix, such that the model can self-reflect to produce better output based on the feedback sequence. The model can optionally receive multiple'), Document(id='28b46728-adbe-47fc-b7a7-82dd0a7abc0c', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='these assumptions in mind, is there any specific aspect of the keyboard control implementation you would like me to clarify?\"'), Document(id='3607e193-50dc-4b51-b4ca-dcd76e8c142d', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='},\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Summary of areas that need clarification:\\\\n1. Specifics of the Super Mario game (e.g. level design, characters, gameplay mechanics)\\\\n2. Details about the MVC components (e.g. which components are in each file)\\\\n3. Keyboard control implementation (e.g. which keys to use, how to handle input)\\\\n\\\\nClarifying question:\\\\nCan you provide more details about the Super Mario game, such as level design, characters, and gameplay mechanics?\"\\n  },\\n  {'), Document(id='c0e093c4-8439-4b57-b686-5a24d58e704a', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"'), Document(id='80f3319d-1d09-475d-a27e-521a4a27deab', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='Prompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions')], 'answer': 'Let\\'s break down how the attention mechanism revolutionized sequence modeling.\\n\\n**Before Attention: The Reign of Recurrence**\\n\\nBefore the advent of attention, recurrent neural networks (RNNs), particularly Long Short-Term Memory (LSTM) networks, were the dominant approach to sequence modeling. \\n\\n* **How RNNs Work:** RNNs process sequences one element at a time, maintaining a hidden state that captures information from previous steps. This \"memory\" allows them to understand context within a sequence.\\n\\n* **Limitations of Recurrence:**\\n\\n    * **Vanishing/Exploding Gradients:** RNNs struggle to learn long-range dependencies because gradients can diminish (vanish) or grow excessively (explode) as they backpropagate through many time steps.\\n\\n    * **Sequential Processing:** RNNs process information sequentially, which can be slow for long sequences.\\n\\n**The Attention Revolution**\\n\\nThe attention mechanism introduced a powerful way to address these limitations:\\n\\n* **Focusing on Relevant Information:** Attention allows the model to selectively focus on specific parts of the input sequence that are most relevant to the task at hand. \\n\\n* **Breaking the Sequential Bottleneck:**  Instead of processing information sequentially, attention can compute relationships between all elements in the sequence in parallel, significantly speeding up training and inference.\\n\\n* **Improved Long-Range Dependencies:** Attention explicitly models the importance of different parts of the input, allowing it to better capture long-range dependencies.\\n\\n**Impact on Sequence Modeling**\\n\\nThe introduction of attention transformed sequence modeling:\\n\\n* **Natural Language Processing (NLP):**  Attention is now a cornerstone of many state-of-the-art NLP models, including machine translation, text summarization, question answering, and language generation.\\n\\n* **Computer Vision:** Attention has also found applications in computer vision tasks such as image captioning and object detection.\\n\\n**In Essence:**\\n\\nAttention provided a more flexible and powerful way to handle sequential data, overcoming the limitations of purely recurrent architectures. It enabled models to learn richer representations of context and relationships within sequences, leading to significant performance improvements in a wide range of applications.\\n\\n\\n'}\n",
      "\n",
      " Sub-questions\n",
      "- Here are some sub-questions that break down the complex query:\n",
      "- * **Sub-question 1:** What were the limitations of recurrent models (like RNNs) in handling long sequences before the introduction of attention mechanisms?\n",
      "- * **Sub-question 2:** How do attention mechanisms address these limitations and improve the performance of sequence modeling tasks?\n",
      "- * **Sub-question 3:** What were the dominant sequence modeling approaches before attention mechanisms gained popularity? (This could explore methods like traditional RNNs, convolutional networks for sequences, etc.)\n",
      "- Let me know if you'd like to explore any of these sub-questions in more detail!\n",
      "\n",
      "Final Answer: Let's break down how the attention mechanism revolutionized sequence modeling.\n",
      "\n",
      "**Before Attention: The Reign of Recurrence**\n",
      "\n",
      "Before the advent of attention, recurrent neural networks (RNNs), particularly Long Short-Term Memory (LSTM) networks, were the dominant approach to sequence modeling. \n",
      "\n",
      "* **How RNNs Work:** RNNs process sequences one element at a time, maintaining a hidden state that captures information from previous steps. This \"memory\" allows them to understand context within a sequence.\n",
      "\n",
      "* **Limitations of Recurrence:**\n",
      "\n",
      "    * **Vanishing/Exploding Gradients:** RNNs struggle to learn long-range dependencies because gradients can diminish (vanish) or grow excessively (explode) as they backpropagate through many time steps.\n",
      "\n",
      "    * **Sequential Processing:** RNNs process information sequentially, which can be slow for long sequences.\n",
      "\n",
      "**The Attention Revolution**\n",
      "\n",
      "The attention mechanism introduced a powerful way to address these limitations:\n",
      "\n",
      "* **Focusing on Relevant Information:** Attention allows the model to selectively focus on specific parts of the input sequence that are most relevant to the task at hand. \n",
      "\n",
      "* **Breaking the Sequential Bottleneck:**  Instead of processing information sequentially, attention can compute relationships between all elements in the sequence in parallel, significantly speeding up training and inference.\n",
      "\n",
      "* **Improved Long-Range Dependencies:** Attention explicitly models the importance of different parts of the input, allowing it to better capture long-range dependencies.\n",
      "\n",
      "**Impact on Sequence Modeling**\n",
      "\n",
      "The introduction of attention transformed sequence modeling:\n",
      "\n",
      "* **Natural Language Processing (NLP):**  Attention is now a cornerstone of many state-of-the-art NLP models, including machine translation, text summarization, question answering, and language generation.\n",
      "\n",
      "* **Computer Vision:** Attention has also found applications in computer vision tasks such as image captioning and object detection.\n",
      "\n",
      "**In Essence:**\n",
      "\n",
      "Attention provided a more flexible and powerful way to handle sequential data, overcoming the limitations of purely recurrent architectures. It enabled models to learn richer representations of context and relationships within sequences, leading to significant performance improvements in a wide range of applications.\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    query=\"How basically attention mechansim changed the overview of recurrent models and what was dominated the sequence modeling before attention mechanism? \"\n",
    "    init_state=RAGState(question=query)\n",
    "    result=graph.invoke(init_state)\n",
    "    print(result)\n",
    "\n",
    "    print(\"\\n Sub-questions\")\n",
    "\n",
    "    for question in result['sub_question']:\n",
    "        print(\"-\",question)\n",
    "\n",
    "    \n",
    "    print(\"\\nFinal Answer:\",result['answer'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
