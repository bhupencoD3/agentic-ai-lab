{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a90b055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from pydantic import BaseModel\n",
    "from langchain.schema import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langgraph.graph import StateGraph,END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fafc44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import init_chat_model\n",
    "from dotenv import load_dotenv\n",
    "os.environ['OPENAI_API_KEY']=os.getenv('OPENAI_API_KEY')\n",
    "os.environ['GROQ_API_KEY']=os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77739041",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=init_chat_model(model='groq:gemma2-9b-it')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6f1fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=TextLoader('research_notes.txt').load()\n",
    "chunks=RecursiveCharacterTextSplitter(chunk_size=500,chunk_overlap=50).split_documents(docs)\n",
    "vector_store=FAISS.from_documents(chunks,OpenAIEmbeddings(model='text-embedding-3-small'))\n",
    "retriever=vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9d088ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGReflectionState(BaseModel):\n",
    "    question:str\n",
    "    retrieved_docs:List[Document]=[]\n",
    "    answer:str=\"\"\n",
    "    reflection:str=\"\"\n",
    "    revised:bool=False\n",
    "    attempts:int=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "873bc41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_docs(state:RAGReflectionState) -> RAGReflectionState:\n",
    "    docs=retriever.invoke(state.question)\n",
    "    return state.model_copy(update={'retrieved_docs':docs})\n",
    "\n",
    "def generate_answer(state:RAGReflectionState) -> RAGReflectionState:\n",
    "    context=\"\\n\\n\".join([doc.page_content for doc in state.retrieved_docs])\n",
    "    prompt=f\"\"\"Use the following context to answer the question:\n",
    "    Context:{context}\\n\\n Question:{state.question}\"\"\"\n",
    "\n",
    "    answer=llm.invoke(prompt).content.strip()\n",
    "    return state.model_copy(update={'answer':answer,'attempts':state.attempts+1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8d09979",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reflect_on_answer(state:RAGReflectionState) -> RAGReflectionState:\n",
    "    prompt=f\"\"\"Reflect on the following answer to see if it fully addresses the question.\n",
    "    State YES if it complete and correct,or NO with an explanation.\n",
    "    Question:{state.question}\\n\\n Answer:{state.answer}\"\n",
    "    \n",
    "    Respond like:\n",
    "    Reflection:YES or NO\n",
    "    Explanation:...\n",
    "    \"\"\"\n",
    "\n",
    "    result=llm.invoke(prompt).content\n",
    "    is_ok=\"reflection:yes\" in result.lower()\n",
    "    return state.model_copy(update={'reflection':result,'revised':not is_ok})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3339a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize(state:RAGReflectionState)->RAGReflectionState:\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76eede21",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder=StateGraph(RAGReflectionState)\n",
    "\n",
    "builder.add_node('retriever',retrieve_docs)\n",
    "builder.add_node('responder',generate_answer)\n",
    "builder.add_node('reflector',reflect_on_answer)\n",
    "builder.add_node('done',finalize)\n",
    "\n",
    "builder.set_entry_point('retriever')\n",
    "builder.add_edge('retriever','responder')\n",
    "builder.add_edge('responder','reflector')\n",
    "builder.add_conditional_edges(\n",
    "    'reflector',\n",
    "    lambda s:'done' if not s.revised or s.attempts >= 2 else 'retriever'\n",
    "\n",
    ")\n",
    "builder.add_edge('done',END)\n",
    "graph=builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27ff790c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Final Answer:\n",
      " The attention mechanism fundamentally changed the landscape of recurrent models by offering a more efficient and effective way to process sequential data.  \n",
      "\n",
      "Here's how:\n",
      "\n",
      "* **Addressing Long-Range Dependencies:** Recurrent models like RNNs, LSTMs, and GRUs struggled to capture relationships between words that were far apart in a sequence due to the sequential nature of their processing. Attention, on the other hand, allows the model to weigh the importance of different words in a sequence, regardless of their position, enabling it to understand long-range dependencies better.\n",
      "\n",
      "* **Parallelization:**  Transformers, which rely on attention, can process entire sequences in parallel, unlike RNNs which process information sequentially. This parallelization significantly speeds up training and makes it possible to work with much larger datasets.\n",
      "\n",
      "* **Conceptual Shift:** Attention marked a paradigm shift away from solely relying on recurrence. It introduced a new way of thinking about how models process information, focusing on selectively attending to relevant parts of the input.\n",
      "\n",
      "Essentially, attention provided a more powerful and scalable alternative to recurrent models, leading to significant advancements in natural language processing and other domains.\n",
      "\n",
      " Reflection Log:\n",
      " Reflection: YES\n",
      "Explanation: The answer comprehensively addresses the question, accurately explaining how the attention mechanism revolutionized recurrent models. It highlights the key benefits: overcoming long-range dependency issues, enabling parallelization, and shifting the paradigm from purely recurrent processing. The explanation is clear, concise, and effectively conveys the impact of attention on the field.  \n",
      "\n",
      "Total Attempts: 2\n"
     ]
    }
   ],
   "source": [
    "if __name__==\"__main__\":\n",
    "    query=\"How basically attention mechansim changed the overview of recurrent models? \"\n",
    "    init_state=RAGReflectionState(question=query)\n",
    "    result=graph.invoke(init_state)\n",
    "\n",
    "    print(\"\\n Final Answer:\\n\",result['answer'])\n",
    "    print(\"\\n Reflection Log:\\n\",result['reflection'])\n",
    "    print('Total Attempts:',result['attempts'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
